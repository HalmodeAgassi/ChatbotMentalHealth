{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ACER\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"GAD-7.csv\"\n",
    "data = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year_1 state_1 general_health                      phq9_1  \\\n",
      "0    2000      MD      Very Good                Several days   \n",
      "1    2001      SC           Good  More than half of the days   \n",
      "2    1999      NJ           Good                Several days   \n",
      "3    1998      NY           Good                Several days   \n",
      "4    2000      PA      Very Good                  Not at all   \n",
      "\n",
      "                       phq9_2                      phq9_3  \\\n",
      "0                Several days                  Not at all   \n",
      "1  More than half of the days            Nearly every day   \n",
      "2                Several days  More than half of the days   \n",
      "3                Several days            Nearly every day   \n",
      "4                Several days                Several days   \n",
      "\n",
      "                       phq9_4            phq9_5        phq9_6  \\\n",
      "0                Several days        Not at all    Not at all   \n",
      "1            Nearly every day  Nearly every day  Several days   \n",
      "2  More than half of the days      Several days  Several days   \n",
      "3            Nearly every day        Not at all  Several days   \n",
      "4                Several days      Several days  Several days   \n",
      "\n",
      "                       phq9_7  ... acha_12months_any_comp     sex  fulltime  \\\n",
      "0  More than half of the days  ...                      2  Female       Yes   \n",
      "1            Nearly every day  ...                      0  Female       Yes   \n",
      "2                Several days  ...                      2  Female       Yes   \n",
      "3                Several days  ...                      2  Female       Yes   \n",
      "4                Several days  ...                      5  Female       Yes   \n",
      "\n",
      "   international                                          race_1  race_2  \\\n",
      "0             No                                             NaN     NaN   \n",
      "1             No                                             NaN     NaN   \n",
      "2             No                                             NaN     NaN   \n",
      "3             No  White - not Hispanic (includes Middle Eastern)     NaN   \n",
      "4             No  White - not Hispanic (includes Middle Eastern)     NaN   \n",
      "\n",
      "               race_3                     race_4  race_5  race_6  \n",
      "0                 NaN  Asian or Pacific Islander     NaN     NaN  \n",
      "1                 NaN  Asian or Pacific Islander     NaN     NaN  \n",
      "2  Hispanic or Latino  Asian or Pacific Islander     NaN     NaN  \n",
      "3                 NaN                        NaN     NaN     NaN  \n",
      "4                 NaN                        NaN     NaN     NaN  \n",
      "\n",
      "[5 rows x 118 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data['general_health'].tolist()\n",
    "labels = data['phq9_severity'].tolist()\n",
    "\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(texts, labels, test_size=0.3, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Convert labels to numerical values\n",
    "label_mapping = {label: idx for idx, label in enumerate(set(labels))}\n",
    "train_labels = [label_mapping[label] for label in train_labels]\n",
    "val_labels = [label_mapping[label] for label in val_labels]\n",
    "test_labels = [label_mapping[label] for label in test_labels]\n",
    "\n",
    "def tokenize_data(texts, labels):\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "    return encodings, labels_tensor\n",
    "\n",
    "train_encodings, train_labels = tokenize_data(train_texts, train_labels)\n",
    "val_encodings, val_labels = tokenize_data(val_texts, val_labels)\n",
    "test_encodings, test_labels = tokenize_data(test_texts, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAD7Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "train_dataset = GAD7Dataset(train_encodings, train_labels)\n",
    "val_dataset = GAD7Dataset(val_encodings, val_labels)\n",
    "test_dataset = GAD7Dataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(set(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_25828\\3438353204.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=lambda p: {\n",
    "        \"accuracy\": accuracy_score(p.label_ids, np.argmax(p.predictions, axis=1))\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b603fc89704398ac051910139c51e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_25828\\362337936.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159f4b732e8b47fd8d80236af8360579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.543938159942627, 'eval_accuracy': 0.2413793103448276, 'eval_runtime': 22.097, 'eval_samples_per_second': 3.937, 'eval_steps_per_second': 0.498, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_25828\\362337936.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841781b99cad439a91886a86ff2a8c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5141088962554932, 'eval_accuracy': 0.3103448275862069, 'eval_runtime': 2.135, 'eval_samples_per_second': 40.749, 'eval_steps_per_second': 5.152, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_25828\\362337936.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_25828\\362337936.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9968cd676024a3c8d6e34bd2a7ce0a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5102463960647583, 'eval_accuracy': 0.27586206896551724, 'eval_runtime': 6.063, 'eval_samples_per_second': 14.349, 'eval_steps_per_second': 1.814, 'epoch': 3.0}\n",
      "{'train_runtime': 853.4689, 'train_samples_per_second': 1.424, 'train_steps_per_second': 0.179, 'train_loss': 1.5030642241434333, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=153, training_loss=1.5030642241434333, metrics={'train_runtime': 853.4689, 'train_samples_per_second': 1.424, 'train_steps_per_second': 0.179, 'total_flos': 2497566742920.0, 'train_loss': 1.5030642241434333, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_25828\\362337936.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069b6291ed7e494080dade9fcd10731b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results: {'eval_loss': 1.4416767358779907, 'eval_accuracy': 0.2988505747126437, 'eval_runtime': 47.3716, 'eval_samples_per_second': 1.837, 'eval_steps_per_second': 0.232, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "test_results = trainer.evaluate(test_dataset)\n",
    "print(\"Test Results:\", test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_25828\\362337936.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98d0a7419514894891e59c5fcd13dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.33      0.04      0.07        27\n",
      "           2       0.33      0.62      0.43        29\n",
      "           3       0.23      0.41      0.30        17\n",
      "           4       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.30        87\n",
      "   macro avg       0.18      0.21      0.16        87\n",
      "weighted avg       0.26      0.30      0.22        87\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ACER\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ACER\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "test_preds = np.argmax(trainer.predict(test_dataset).predictions, axis=1)\n",
    "print(classification_report(test_labels, test_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./gad7_bert_model\\\\tokenizer_config.json',\n",
       " './gad7_bert_model\\\\special_tokens_map.json',\n",
       " './gad7_bert_model\\\\vocab.txt',\n",
       " './gad7_bert_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./gad7_bert_model\")\n",
    "tokenizer.save_pretrained(\"./gad7_bert_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.30\n",
      "Recall: 0.21\n",
      "F1 Score: 0.16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(test_labels, test_preds)\n",
    "recall = recall_score(test_labels, test_preds, average=\"macro\")\n",
    "f1 = f1_score(test_labels, test_preds, average=\"macro\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
